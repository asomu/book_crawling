# 프로젝트 분석 보고서: 이미지 크롤링 프로젝트

## 1. 프로젝트 개요

이 프로젝트는 한국 온라인 서점에서 특정 도서들의 커버 이미지를 수집(크롤링)하는 것을 목적으로 합니다. `main.py`를 중심으로 동작하며, Selenium을 사용하여 웹 브라우저를 자동화하고, ISBN 목록을 기반으로 이미지를 다운로드합니다.

## 2. 주요 파일 및 역할

- **`main.py`**: 프로젝트의 진입점(Entry Point)입니다. 전체 크롤링 과정을 관리하는 `book_manager` 클래스를 정의하고 실행합니다.
- **`book_scraper.py`**: 실제 웹 스크래핑 로직을 담고 있을 것으로 추정됩니다. `BookScraperFactory`를 통해 특정 서점(예: 교보문고)에 맞는 스크래퍼 객체를 생성하는 팩토리 패턴을 사용합니다.
- **`chrome_controler.py`**: Selenium WebDriver를 생성하고 초기화하는 역할을 합니다. 로그인 정보가 필요한 경우, 이 단계에서 처리될 가능성이 높습니다.
- **`book_info_save.py`**: `Site` (서점 종류), `Mode` (동작 모드) 등과 같은 열거형(Enum) 타입을 정의하여 코드의 가독성과 유지보수성을 높입니다.
- **`login.yaml`**: 서점 사이트 로그인에 필요한 아이디와 비밀번호를 저장하는 설정 파일입니다.
- **`isbn.txt`**: 크롤링할 도서의 ISBN 번호 목록을 담고 있는 텍스트 파일입니다.

## 3. 동작 순서 분석

프로젝트는 다음 순서로 동작합니다.

1.  **로그인 정보 로드**: `get_login_info()` 함수가 `login.yaml` 파일에서 사용자 아이디와 비밀번호를 읽어옵니다.
2.  **`book_manager` 객체 생성**: `main` 실행 블록에서 `book_manager` 클래스의 인스턴스를 생성합니다. 이때, 앞서 읽어온 로그인 정보를 전달합니다.
3.  **크롤링 실행 (`run` 메소드)**:
    a. `get_driver()`를 호출하여 로그인 정보로 초기화된 Selenium WebDriver를 준비합니다.
    b. `isbn.txt` 파일을 열어 크롤링할 책들의 ISBN 목록을 한 줄씩 읽어옵니다.
    c. 각 ISBN에 대해 반복 작업을 수행합니다.
    d. `BookScraperFactory`를 사용하여 현재는 **교보문고(`Site.Kyobo`)**에 해당하는 스크래퍼 객체를 생성합니다.
    e. 생성된 스크래퍼 객체의 메소드(`save_detailed_image`, `save_cover_image`)를 호출하여 상세 이미지와 여러 종류의 커버 이미지를 다운로드하여 저장합니다.

## 4. 프로젝트 구조적 특징

- **팩토리 패턴(Factory Pattern)**: `BookScraperFactory`를 사용하여 향후 교보문고 외에 다른 온라인 서점(Yes24, 알라딘 등)을 쉽게 추가할 수 있는 확장성 있는 구조를 가집니다.
- **역할 분리**: `main.py`는 전체 흐름을 제어하고, `book_scraper.py`는 실제 데이터 추출을, `chrome_controler.py`는 브라우저 제어를 담당하는 등 역할이 명확하게 분리되어 있습니다.
- **설정 파일 사용**: 로그인 정보나 대상 ISBN 목록을 코드에서 분리하여 `yaml`과 `txt` 파일로 관리함으로써, 코드 수정 없이 대상을 변경할 수 있습니다.

## 5. 개선 및 고려사항

- **에러 처리**: 현재 `get_login_info` 외에 크롤링 중 발생할 수 있는 다양한 예외(예: 페이지 로드 실패, 찾으려는 요소 없음)에 대한 처리가 부족해 보입니다. 각 단계에 `try-except` 블록을 추가하여 안정성을 높일 수 있습니다.
- **대기 시간**: `time.sleep(5)`와 같이 고정된 시간으로 대기하는 부분은 네트워크 상태나 페이지 로딩 속도에 따라 불안정할 수 있습니다. Selenium의 `WebDriverWait`를 사용하여 특정 요소가 나타날 때까지 명시적으로 기다리는 방식으로 개선할 수 있습니다.
